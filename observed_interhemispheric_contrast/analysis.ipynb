{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d171b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import xesmf as xe\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import pymannkendall as mk\n",
    "import statsmodels.api as sm\n",
    "import metpy.calc as mpcalc \n",
    "from metpy.units import units \n",
    "from scipy import stats, interpolate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['font.family'] = 'arial'  \n",
    "mpl.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e031582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select TC data\n",
    "def IBTrACS_Select_TS(AGENCY='USA'):\n",
    "    data = pd.read_csv('/mnt/h/Data/IBTrACS/ibtracs.ALL.list.v04r01.csv', keep_default_na=False) \n",
    "   \n",
    "    data = data[data['NATURE'].isin(['TS'])]  \n",
    "    \n",
    "    columns = ['SID', 'SEASON', 'BASIN', 'NAME', 'ISO_TIME', AGENCY + '_LAT', AGENCY + '_LON', AGENCY + '_WIND', AGENCY + '_PRES']\n",
    "    if AGENCY == 'USA':\n",
    "        columns.append(AGENCY + '_SSHS')\n",
    "    elif AGENCY == 'CMA':\n",
    "        columns.append(AGENCY + '_CAT')\n",
    "    elif AGENCY == 'TOKYO':\n",
    "        columns.append(AGENCY + '_GRADE')\n",
    "    data = data[columns]\n",
    "    \n",
    "    data['SEASON'] = data['SEASON'].astype('int')\n",
    "    data = data[data['SEASON'].isin(range(1980, 2021))] # Select years\n",
    "\n",
    "    data = data[~data['BASIN'].isin(['SA'])]\n",
    "    data['BASIN'] = data['BASIN'].replace({'WP': 'WNP', 'EP': 'ENP'})\n",
    "\n",
    "    data = data[data['NAME'] != 'UNNAMED']    # Select named TCs\n",
    "    \n",
    "    data['ISO_TIME'] = pd.to_datetime(data['ISO_TIME']) \n",
    "    data = data[data['ISO_TIME'].dt.hour.isin([0, 6, 12, 18])]\n",
    "  \n",
    "    data = data[data[AGENCY + '_WIND'] != ' ']\n",
    "\n",
    "    data['SID'] = data['SID'].astype('string')\n",
    "    data['BASIN'] = data['BASIN'].astype('string')\n",
    "    data['NAME'] = data['NAME'].astype('string')\n",
    "    data[AGENCY + '_LAT'] = data[AGENCY + '_LAT'].astype('float')\n",
    "    data[AGENCY + '_LON'] = data[AGENCY + '_LON'].astype('float')\n",
    "    \n",
    "    return data\n",
    "\n",
    "JTWC_data = IBTrACS_Select_TS(AGENCY='USA')\n",
    "JTWC_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin statistics\n",
    "data_TCF = JTWC_data.copy()\n",
    "data_TCF = data_TCF.drop_duplicates(subset='SID', keep='first')\n",
    "data_TCF['USA_LON'] = data_TCF['USA_LON'].apply(lambda x: x if x >= 0 else x + 360)\n",
    "\n",
    "data_TCF['Hemisphere'] = data_TCF['USA_LAT'].apply(lambda x: 'NH' if x > 0 else 'SH')\n",
    "annual_counts = data_TCF.groupby('SEASON')['SID'].nunique().reset_index()\n",
    "annual_counts.columns = ['SEASON', 'All']\n",
    "NH_counts = data_TCF[data_TCF['Hemisphere'] == 'NH'].groupby('SEASON')['SID'].nunique().reset_index()\n",
    "NH_counts.columns = ['SEASON', 'NH']\n",
    "south_counts = data_TCF[data_TCF['Hemisphere'] == 'SH'].groupby('SEASON')['SID'].nunique().reset_index()\n",
    "south_counts.columns = ['SEASON', 'SH']\n",
    "basin_counts = data_TCF.groupby(['SEASON', 'BASIN'])['SID'].nunique().unstack(fill_value=0).reset_index()\n",
    "\n",
    "result = annual_counts.merge(NH_counts, on='SEASON', how='left')\n",
    "result = result.merge(south_counts, on='SEASON', how='left')\n",
    "result = result.merge(basin_counts, on='SEASON', how='left')\n",
    "result = result[['SEASON', 'All', 'NH', 'SH', 'WNP', 'ENP', 'NA', 'SI', 'SP', 'NI']]\n",
    "result\n",
    "\n",
    "# save time series of TCF\n",
    "# result.to_csv('H:/processedData/TimeSeries_TCF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9aa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate monthly TCF\n",
    "lat_bins = np.arange(91.25, -91.25, -2.5)   \n",
    "lon_bins = np.arange(-1.25, 361, 2.5) \n",
    "\n",
    "monthly_data = []\n",
    "for year in sorted(data_TCF['SEASON'].unique()):\n",
    "    for month in sorted(data_TCF['MONTH'].unique()):\n",
    "        data_month = data_TCF[(data_TCF['SEASON'] == year) & (data_TCF['MONTH'] == month)]\n",
    "        res = pd.DataFrame(index=lat_bins[:-1], columns=lon_bins[:-1], data=0)\n",
    "        \n",
    "        for tc_id in data_month['SID'].unique():\n",
    "            data_tc_first = data_month[data_month['SID'] == tc_id].iloc[0]\n",
    "            lat = data_tc_first['USA_LAT']\n",
    "            lon = data_tc_first['USA_LON']\n",
    "            lat_index = np.digitize(lat, lat_bins) - 1\n",
    "            lon_index = np.digitize(lon, lon_bins) - 1\n",
    "\n",
    "            if (0 <= lat_index < len(lat_bins) - 1) and (0 <= lon_index < len(lon_bins) - 1):\n",
    "                lat_grid = lat_bins[lat_index]\n",
    "                lon_grid = lon_bins[lon_index]\n",
    "                res.loc[lat_grid, lon_grid] += 1\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            res.values,\n",
    "            dims=['lat', 'lon'],\n",
    "            coords={\n",
    "                'lat': lat_bins[:-1] + 1.25,  \n",
    "                'lon': lon_bins[:-1] + 1.25,   \n",
    "            }\n",
    "        )\n",
    "        monthly_data.append(da)\n",
    "\n",
    "Monthly_TCF_2p5 = xr.concat(monthly_data, dim='time')\n",
    "Monthly_TCF_2p5 = Monthly_TCF_2p5.assign_coords(time=pd.date_range(start='1980-01', periods=492, freq='MS'))\n",
    "\n",
    "# save Monthly TCF\n",
    "Monthly_TCF_2p5.name = 'tcf'\n",
    "Monthly_TCF_2p5.attrs['name'] = 'monthly tropical cyclone frequency'\n",
    "Monthly_TCF_2p5.attrs['units'] = 'unitless'\n",
    "Monthly_TCF_2p5 = Monthly_TCF_2p5.astype(np.float32)\n",
    "Monthly_TCF_2p5.coords['lat'] = np.arange(88.75, -88.75 - 2.5, -2.5)\n",
    "Monthly_TCF_2p5.coords['lon'] = np.arange(1.25, 358.75 + 2.5, 2.5)\n",
    "# Monthly_TCF_2p5.to_netcdf('H:/ProcessedData/Monthly_TCF_2p5.nc')\n",
    "\n",
    "# calculate annual TCF\n",
    "years = Monthly_TCF_2p5.time.dt.year\n",
    "months = Monthly_TCF_2p5.time.dt.month\n",
    "Annual_TCF_2p5 = []\n",
    "for year in np.unique(years):\n",
    "    year_data = Monthly_TCF_2p5.sel(time=Monthly_TCF_2p5.time.dt.year == year)\n",
    "    \n",
    "    # NH\n",
    "    nh_mask = (year_data.lat > 0) & (year_data.time.dt.month.isin([6, 7, 8, 9, 10, 11]))\n",
    "    nh_data = year_data.where(nh_mask, drop=True)\n",
    "    \n",
    "    # SH\n",
    "    sh_mask = (year_data.lat < 0) & (year_data.time.dt.month.isin([12, 1, 2, 3, 4, 5]))\n",
    "    sh_data = year_data.where(sh_mask, drop=True)\n",
    "    \n",
    "    combined_data = xr.concat([nh_data, sh_data], dim='lat').sortby('lat', ascending=False)\n",
    "    yearly_avg = combined_data.sum(dim='time', keep_attrs=True)\n",
    "    yearly_avg = yearly_avg.assign_coords(year=year) \n",
    "    Annual_TCF_2p5.append(yearly_avg)\n",
    "\n",
    "# save annual TCF\n",
    "Annual_TCF_2p5 = xr.concat(Annual_TCF_2p5, dim='year')\n",
    "Annual_TCF_2p5['year'] = pd.to_datetime(np.unique(years), format='%Y')\n",
    "Annual_TCF_2p5 = Annual_TCF_2p5.rename({'year': 'time'})\n",
    "Annual_TCF_2p5.attrs['name'] = 'annual tropical cyclone frequency'\n",
    "# Annual_TCF_2p5.to_netcdf('/mnt/h/ProcessedData/Annual_TCF_2p5.nc')\n",
    "\n",
    "# calculate TCF spatial trends\n",
    "trend = np.zeros_like(Annual_TCF_2p5.isel(time=0))\n",
    "p_value = np.zeros_like(Annual_TCF_2p5.isel(time=0))\n",
    "for lat in range(len(Annual_TCF_2p5.lat)):\n",
    "    for lon in range(len(Annual_TCF_2p5.lon)):\n",
    "        y = Annual_TCF_2p5[:, lat, lon].values\n",
    "        res = stats.linregress(np.arange(len(Annual_TCF_2p5.time)), y)\n",
    "        trend[lat, lon] = res.slope * 10\n",
    "        p_value[lat, lon] = res.pvalue\n",
    "trend = np.where(trend == 0, np.nan, trend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
